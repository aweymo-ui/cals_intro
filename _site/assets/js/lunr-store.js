var store = [ 
    
    
    { 
        "url": "/geolocation/content/1_intro.html",
        "title": "Introduction",
        "text": "Hello, my name is Andrew Weymouth and I have worked with the University of Idaho Library as the Digital Initiatives Librarian in the Center for Digital Inquiry and Learning (CDIL) department since the fall of 2023. My work generally consists of creating and maintaining our digital collections, collaborating on projects with fellowship recipients, helping to rethink processes and introducing new digital scholarship tools to the department. &#10042; Why Geolocate? To start, I’d like to share an example of how geolocation, or the process of identifying where a visual resource was captured, can enhance your research. In the summer of 2023, I was writing about Filipino American “Alaskeros” who migrated seasonally between California, Oregon, Washington, and Alaska to work in salmon canneries. Salvador Caballero (right) and a companion, Seattle, Washington, September 18, 1917. Courtesy of Teresa Duran Verfaillie and FANHS.. One of the only first person resources I was able to find from this community of migratory workers was a scrapbook of an Alaskero named Salvador Caballero, housed at the Filipino American National Historical Society in Seattle. Caballero’s photos offer a candid view of migratory life, but only a few of the hundreds of images include location notes, making it challenging to fully grasp the insights they could provide about travel, labor, unions, and daily life. Though the platform has been in development for almost 20 years, continued improvements in satellite imagery and recent advancements in 3D technology have made even remote areas of Alaska identifiable through Google Earth. A note in Caballero’s scrapbook mentioning the “Karluk Cannery” allowed me to use a basic geolocation technique: tracing the coastline of the southeastern Alaskan island of Karluk in Google Earth to match natural landforms in the photo collection. When working with an island or similarly contained area, this process is relatively simple, as coastal rock formations tend to remain consistent over time. Google Earth rendering of geological features beside one of the archival photos on Karluk, ca. 1938. Photograph by Salvador Caballero, courtesy of FANHS. &#10042; By connecting landform, monuments, bodies of water and building footprints between photographs and satellite imagery, an entirely new layer of historical context can be drawn from an archival image. Travel distances can reveal how much free time workers had, the layout of housing and its proximity to indigenous communities can shed light on race and class dynamics. Additionally, analyzing the distance between the cannery site and the fishing grounds located further south helps us understand day-to-day business practices and the logistical challenges faced by workers. (Left) Alutiiq woman holding a cat outside the cannery workers bunkhouse village, Kodiak Island, Alaska, ca. 1938. (Right) Alutiiq children fishing salmon from the Karluck River, Kodiak Island, Alaska, ca. 1938. Photograph by Salvador Caballero, courtesy of FANHS. This presentation introduces tools and methods for geolocation to help you enrich your own research and make new academic discoveries using visual resources. The following sections have been organized as a kind of workflow: moving from the most intuitive, straight-forward to more complicated, technical approaches. Note All of the tools I will be covering today are freely available resources you can access as a U of I student, though some will require you to submit an form beforehand stating that you will be using them for non-profit purposes."
    },
    { 
        "url": "/geolocation/content/2_text.html",
        "title": "Text Analysis",
        "text": "Maybe the simplest place to begin is use the text provided within the image you are attempting to locate. Within the image, this could be building names, signs or advertisements or handwritten captions if you are working with a scrapbook. Even if only one in two hundred photos is labeled, that small amount of information is enough to begin making connections. You can try searching these terms (using Boolean quotes for exact phrases) in Google, but you’ll usually find that the algorithm is too broad for this type of historical research. Instead, try using the Newsbank newspaper resource available to you through the University, and refine results by adding time and location perameters. Contents: First Example | Second Example | Third Example | Fourth Example The examples I will be using for this presentation are from a scrapbook in our Special Collections titled Unidentified Family Album, 1920-1939 which I will use to illustrate the strengths and limitations of digital geolocation tools. Let’s go through a few methods for identifying locations through text elements: &#10042; First Example Photograph PG070-18-02 from Unidentified Family Album and detail, 1920-1939, Courtesy U of I Special Collections Searching for “Raymond Cafe” and narrowing it down by adding “Idaho,” we discover that this photo was taken on Main Street in Lewiston, and that the cafe’s owner was a prominent figure in Idaho’s Chinese American history. By examining the float next to the building, we can also determine that the photo was captured during the now-defunct Rose Parade, which took place annually in mid-June. Two participants in the Lewiston Rose Parade, June 14, 1914. Courtesy Lewiston Tribune. &#10042; Second Example Photograph PG070-66-01 from Unidentified Family Album and detail, 1920-1939, Courtesy U of I Special Collections While there are actually a few structures here that are identifiable through reverse image searching, we can also identify this location with text. Zooming in on this little storefront, we can make out the business name “Butterfield-Elder Implement Company,” which appears in the article Federal Buildings of North Idaho as a business located in Moscow. Given the specificity of the name and its proximity to other photos in the collection, we can confidently conclude that this is an overhead shot of Moscow. Newspaper clipping, August 8, 1906. Courtesy Idaho Statesman &#10042; Third Example Photograph PG070-14-01 from Unidentified Family Album and detail, 1920-1939, Courtesy U of I Special Collections In geolocation, it is important to search for alternate spellings, especially in the case of non-english languages which may be “simplified” in english speaking newspapers. In this example, the Kaga Maru steamship appears to be one word on the ship but is written as two newspaper accounts, where it is advertised as docking at many points along China, Japan and Southeast Asia but connected only stateside in Seattle. Given the geographic footprint of the other photos in this scrapbook and the proximity of the photo with other images that resemble the city, we can be fairly confident that is where this was taken. Newspaper clipping, July 24, 1901, Courtesy The Oregonian &#10042; Fourth Example Photograph PG070-14-01 from Unidentified Family Album and detail, 1920-1939, Courtesy U of I Special Collections Finally, the most easily identifiable of the bunch is certainly the Giant Geyser of Yosemite National Park in Wyoming, but this does help establish the larger parameters of area that the scrapbook is likely to be within: From a base in Moscow, southeast to Yellowstone and northwest to Seattle. Geographic span of the places we have identified so far. Getting these relatively simple and definitive items out of the way helps reduce the size of our potential map as we move forward to the next geolocation method."
    },
    { 
        "url": "/geolocation/content/3_reverse.html",
        "title": "Reverse Image Searching",
        "text": "Similar to Google Earth’s satellite imaging, reverse image searching has been under development for many years, but recent innovations have significantly improved its accuracy. This technology works by using an algorithm to analyze an image’s content and create a unique digital signature, or “fingerprint.” The algorithm then searches for similar fingerprints within the platform’s database. The first publicly available reverse image search engine, TinEye, was launched in 2008, followed by Russia-based Yandex, and then Google and Bing. &#10042; For an exact image match, such as when verifying the copyright of an image without metadata, I recommend using TinEye When you need to identify an area that may be taken from a slightly different angle, lighting or proximity, I recommend using Google Lens or Bing Visual Search These algorithms excel because they are able to detect particular digital signatures that align with your image from an otherwise contrasting image, such as one distinctive structure or the particular shape of a skyline While Yandex is by some accounts the most accurate of all of these tools for geolocation, I’ve found that search results skew heavily towards locations in Russia and Europe Here are some examples of the types of things reverse image searching excels at and some of the things it struggles with: &#10042; Strengths Dramatically distinct patterns in the landscape, as in this Swallows Nest Rock on Snake River located in Clarkston, Washington. (Left) Photograph PG070-04-03 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. (Right) Swallows Nest Rock on Snake River postcard, 1938. Courtesy U of I Special Collections Many of these roadside attraction type images are readily identifiable simply because the lookout areas often mean that people have been taking the same photos of the same things from the same perspective for 100 plus years, so there are plenty of digital fingerprints in any given database to reference! Distinct patterns in the built environment are also effective. (Left) Photograph PG070-66-01 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. (Right) Birdseye view of business district from corner of 6th and Jackson Streets. Moscow, Idaho. 1920. Courtesy U of I Special Collections The same image we located through text analysis is also identifiable through reverse image searching. Although we don’t have an explanation of what the Google Lens algorithm matched between this photo (PG070-66-01) and this one, taken from a significantly different angle, it would be surprising if it wasn’t the distinctively shaped little white building on the bottom left of both images with its heavily contrasted doors and windows creating a unique digital fingerprint. (Left) Photograph PG070-18-01 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. (Right) Spalding (Idaho), 1952. Courtesy U of I Special Collections. The pattern of the bridge and geological markings helped identify the now demolished Spalding Bridge on the Clearwater River east of Lewiston (PG070-18-01) and the festivities indicate this may have taken place during the opening ceremony of the structure in 1923. &#10042; Weaknesses Popular text against nondescript surroundings Photograph PG070-18-01 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. There were hundreds of unrelated National Geographic results that were generated for this image, but none having to do with this strange piece of roadside architecture. Residential architecture Photograph PG070-16-03 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. These types of houses were literally sold in catalogs, making these digital fingerprints too universal to identify with reverse image searching. Sparsely populated areas Photograph PG070-23-01 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. The lack of distinctive digital signatures, and the higher likelihood that the area has possibly never been photographed before and the success rate of reverse image searching much lower. Pervasive industrial structures Photograph PG070-23-01 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. Like residential architecture, reverse image search tools struggle with common industrial structures, which often lack distinctive digital fingerprints and are often so large that they can obscure valuable context in the skyline."
    },
    { 
        "url": "/geolocation/content/4_landmark.html",
        "title": "Landmark Identification",
        "text": "If these last two methods were unsuccessful you may want to use a resource named Overpass Turbo. The platform centers around tagged landmarks in a geographic area. Landmarks can include natural features (like mountains or rivers), historical sites, monuments, buildings, types of businesses and other structures that are differentiated by cultural, historical, or aesthetic purposes. Overpass Turbo is designed to create and run queries on OpenStreetMap, a collaborative, volunteer generated geographic database that has been tagging these types of landmarks for over 20 years. &#10042; In addition to volunteer tagging, the database also pulls from infrastructural public datasets and aerial imagery. Overpass Turbo runs on the Overpass API query language to search for an extremely wide array of different built and natural environmental features. For example, here is a map I created of all of the landmarks identified of fast food “amenities” here in Moscow. Click here to explore. (It may take a moment to load.) Overpass Turbo map of Moscow Fast Food locations &#10042; When geolocating with landmarks, it’s essential to consider if you have enough reference points to accurately identify a location. In triangulation you have (you guessed it) three points of reference that you can use to measure angles and distances between landmarks to identify an area. These points of reference can be landmarks or distinctive elements of the skyline. Photograph PG070-04-03 from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. Take this photo from the scrapbook collection for instance. Because this photograph is located in the scrapbook between two others we can identify as Yellowstone National Park, there’s a good chance it is as well. Using the following code, we can search this area for the water tower we see on the left. [out:json][timeout:25]; // Define the bounding box for the area around Yellowstone National Park ( node[\"man_made\"=\"water_tower\"](44.0030,-111.2045,45.0030,-109.2045); ); // Output the results out body; &gt;; out skel qt; Resulting Overpass Turbo map with a single node denoting the water tower in Yosemite National Park Google Earth rendering of the water tower from the perspective of the photograph. While we find that there is a water tower located within an area that would likely have had the power line we see running across the block in the background, there aren’t enough landmarks or clearly visible landforms in the background of the image to orient us in space. &#10042; First National Bank with Mullan Monument, n.d. Courtesy U of I Special Collections. In contrast, this photograph would be an example of an image that is ideal for triangulation (setting aside the fact that we actually know this is located in Mullan, Idaho). We have a monument in the road, a series of street lamps, a structure that resembles a 19th century bank and a landform in the background with a fairly distinct shape. Using the OpenStreetMap language again, we can search for these elements within the state of Idaho: [out:json][timeout:25]; // Define the area of Idaho using its boundary area[\"admin_level\"=\"4\"][\"name\"=\"Idaho\"]-&gt;.searchArea; // Query for street lamps ( node[\"highway\"=\"street_lamp\"](area.searchArea); way[\"highway\"=\"street_lamp\"](area.searchArea); relation[\"highway\"=\"street_lamp\"](area.searchArea); ); // Query for monuments ( node[\"historic\"=\"monument\"](area.searchArea); way[\"historic\"=\"monument\"](area.searchArea); relation[\"historic\"=\"monument\"](area.searchArea); ); // Query for banks ( node[\"amenity\"=\"bank\"](area.searchArea); way[\"amenity\"=\"bank\"](area.searchArea); relation[\"amenity\"=\"bank\"](area.searchArea); ); // Output the results out body; &gt;; out skel qt; Overpass Turbo map with many nodes denoting all of the banks in Idaho. The map this code generates is indicative of some of the shortcomings OpenStreetMaps has as a collaborative, volunteer driven platform: just because there is a tag for a type of landmark doesn’t mean that there will be consistent data for it. While there are 3439 banks identified here, we have no monuments or street lamps and even the bank in Mullan isn’t tagged. Overpass Turbo excels in densely populated areas, but it tends to be less reliable in rural regions, often resulting in significant data gaps for many landmarks."
    },
    { 
        "url": "/geolocation/content/5_aerial.html",
        "title": "Aerial Timelapse",
        "text": "Another challenge in geolocation is identifying photographs of structures that have since been demolished. Creating a time-lapse using historical aerial photography can help you understand when and where significant features, such as bridges, buildings, and natural areas, were still standing. &#10042; Contents: Platform Comparison | Google Earth Engine | Output Comparison Platform Comparison While there have been aerial photography initiatives active for over 100 years and major digital repositories now contain over 900 collections (referred to as ‘datasets’ in the GIS discipline), compositing this data together to form a comprehensive time lapse of a defined area is surprisingly difficult. Here are a few different freely available resources and their different strengths and weaknesses. Beginning with a few bad ones you don’t want to spend your time on (like I did): Platform Strengths Weaknesses Directions Google Earth Pro This desktop version of Google Earth is where some older online references will point you towards for this functionality, but this is an outdated model that Google appears to have abandoned for more contemporary platforms The “Movie Maker” tool that would carry out this action no longer appears to be functional USGS Earth Explorer If you want to source aerial photographs and put them into a time lapse manually using a resource like Adobe Premiere or After Effects, this database contains material that predates many of the other resources, sometimes as far back as 1950, whereas the others only reach as far back as 1980. As mentioned, only still images can be exported, so the time lapse function and overlaying images need to be done manually Extremely non-intuitive interface. Google Earth Very simple to use Good date range, reaching all the way back to 1984 in this example Landmark names help orient the viewer Very poor fidelity No video export functionality Enter your location Select the Layers button on the bottom left hand of the screen Toggle the time lapse button Adjust speed as wanted Screen capture to create video ArcGIS World Imagery Wayback Better fidelity Even more intuitive controls Historical reach isn’t very far; only about 10 years depending on the area. Enter location Press the play button and adjust speed as desired Export video directly or upload to cloud &#10042; Google Earth Engine While I found the learning curve for this resource steep, its adaptability, variety of datasets, and convenient export settings make it an excellent choice for geolocation. Like the USGS Earth Explorer, you’ll need to sign a waiver confirming that you’ll use the resource for non-profit purposes, but you should gain near-immediate access after signing. The interface resembles a text editor familiar to those with coding experience. The left pane displays the scripts you’ve written, along with examples of other scripts you can automatically generate to aid your learning of the programmatic language. You’ll also find the Google Earth Engine documentation here for specific functionalities. The center pane is where you write and run your code, while the right pane features a console that functions as a terminal, displaying error messages and printing data after script execution. The task pane lists the scripts you’ve run along with their status. The intention of the code is to create a time lapse over Moscow, ID, covering the longest possible time span. // Define the center of the 83843 area code in Moscow, Idaho var moscowCenter = ee.Geometry.Point([-117.0028, 46.7326]); // Approximate center of 83843 // Define a square boundary around Moscow, covering an area of interest (e.g., 5 square miles ~ 12.95 square km) var moscowBoundary = moscowCenter.buffer(1810).bounds(); // 1810 meters radius approximates a 5 square mile area // Load the ImageCollection and filter by the defined area var collection = ee.ImageCollection('USDA/NAIP/DOQQ') .filterBounds(moscowBoundary) .sort('system:time_start'); To start, we will define our geographic perimeter around the 83843 area code. Next, we will specify the dataset to use for creating this visualization. Although Google Earth Engine offers over 900 datasets, I found it challenging to combine them as a beginner, likely due to differences in metadata and color outputs. Therefore, for this script, we will focus solely on the National Agriculture Imagery Program dataset, which dates back to around 1980. // Get the earliest image var earliestImage = collection.first(); var earliestDate; if (earliestImage) { earliestDate = ee.Date(earliestImage.get('system:time_start')).format('YYYY-MM-dd').getInfo(); print('Earliest Available Date:', earliestDate); // Define the updated date range var startDate = earliestDate; // Use earliest date found var endDate = '2024-06-01'; // End date // Filter the ImageCollection with the updated date range collection = collection.filterDate(startDate, endDate); // Function to get the image with the largest area for each year var getLargestImagePerYear = function(year) { var yearlyCollection = collection.filter(ee.Filter.calendarRange(year, year, 'year')); // Compute the intersection of each image with the boundary and calculate area var largestImage = yearlyCollection.map(function(image) { var intersection = image.geometry().intersection(moscowBoundary, 1); // Added error margin of 1 meter return image.set({'intersectionArea': intersection.area()}); }).sort('intersectionArea', false).first(); // Sort by area and get the largest return largestImage; }; // Get the years from the collection var years = ee.List(collection.aggregate_array('system:time_start')) .map(function(date) { return ee.Date(date).get('year'); }).distinct(); // Map over years to get the largest image per year var largestImagesCollection = ee.ImageCollection(years.map(getLargestImagePerYear)) .sort('system:time_start'); // Ensure chronological order Moving ahead, I encountered another complication: not all satellite photographs that capture parts of the area offer complete coverage, leaving distracting gaps in some of the earlier iterations of the code. To address this, I adjusted the code to request only the largest image for each year, ensuring optimal coverage and a better yield of images. A little farther down in the script, we are assembling these images chronologically, from earliest to most recent, and compiling them into a video format for export in red, green, and blue (RGB) color formatting. // Function to prepare images for video export and add date metadata var prepareForExport = function(image) { var date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'); // Visualize the image with appropriate bands and scale var visualImage = image.visualize({ bands: ['R', 'G', 'B'], min: 0, max: 255 }); // Annotate the image with the date (add metadata) return visualImage.set({'date': date}); }; // Apply the function to the largest images collection var annotatedCollection = largestImagesCollection.map(prepareForExport); // Print dates of all images to the console in chronological order annotatedCollection.aggregate_array('date').evaluate(function(dates) { print('Image Dates:', dates); }, function(error) { print('Error:', error); }); Ideally, I wanted to create code that would automatically overlay the date information onto each photograph, providing viewers with a better frame of reference. However, the best I could achieve was to have this metadata “printed” in the console when the script runs. This data can then be easily added to the frames using video editing software like Adobe Premiere. // Define video export parameters with increased display time var videoParams = { region: moscowBoundary, dimensions: 900, // Adjust as needed crs: 'EPSG:3857', framesPerSecond: 0.5, // Increase time on screen to 2 seconds per image description: 'Moscow_TimeLapse', folder: 'EarthEngine' }; // Export the video Export.video.toDrive({ collection: annotatedCollection, description: videoParams.description, folder: videoParams.folder, dimensions: videoParams.dimensions, framesPerSecond: videoParams.framesPerSecond, crs: videoParams.crs, region: videoParams.region }); } else { print('No images found within the specified boundary.'); } &#10042; Finally, one of the convenient things about working with Google Earth Engine is that you can export videos, images and interactive maps you create directly into your Google Drive account. Additionally exported video files can be converted into GIF files and loaded onto project sites like we see below. Output Comparison Gif of Google Earth time lapse over Moscow, Idaho demonstrating lower fidelity. Gif of ArcGIS World Imagery time lapse over Moscow, Idaho, demonstrating improved fidelity but shortened, more contemporary time span. Gif of Google Earth Engine time lapse over Moscow, Idaho, demonstrating improved fidelity and increased time span but difficulty of framing due to the variety of datasets."
    },
    { 
        "url": "/geolocation/content/6_conclusion.html",
        "title": "Conclusion",
        "text": "Photograph PG070-44-03, Lyle, Washington from Rowena Loops, from Unidentified Family Album, 1920-1939, Courtesy U of I Special Collections. &#10042; All of the tools and methods that we covered in this workshop can, of course, be applied to studies outside of the archive. Locating visual resources is just a use case. These methods can be used to track wildlife migration patters in environmental sciences, analyze spatial data in infrastructure development, optimize delivery routes in transportation and logistical work, analyze spatial relationships between artifacts in archaeology or, in the case of the Overpass Turbo map we looked at earlier, quickly identify the nearest junk food. Thank you for your time."
    },
    { 
        "url": "/geolocation/",
        "title": "Home",
        "text": "Presentation Transcript and Slides for the 2024 U of I Information Landscape Series slides This workshop, part of the 2024 University of Idaho Information Landscapes series, will teach attendees how to identify archival images without location metadata using text analysis, reverse image search, landmark identification, and aerial time-lapse tools. The intention of this work is to introduce freely accessible tools and methods to researchers new to the discipline, providing a foundational understanding rather than comprehensive proficiency. Contents: Introduction Text Analysis Reverse Image Searching Landmark Identification Aerial Timelapse Conclusion Content: CC BY-NC-ND 4.0 Andrew Weymouth 2024 (get source code). Theme: Variation on workshop-template-b by evanwill"
    }];
